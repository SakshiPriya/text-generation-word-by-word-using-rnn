{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wordbyword.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/SakshiPriya/text-generation-word-by-word-using-rnn/blob/master/wordbyword.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "E4E2Tvp2dGfC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "from  nltk.corpus import gutenberg\n",
        "from nltk import word_tokenize\n",
        "import unicodedata\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BfA0ubs6dxtF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "d9a0d167-a70c-405b-b97b-c5c4d22f531b"
      },
      "cell_type": "code",
      "source": [
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /content/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /content/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "gfBDELcxeB8-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data=gutenberg.raw('shakespeare-hamlet.txt')\n",
        "data=unicodedata.normalize('NFKD', data).encode('ascii','ignore')\n",
        "dat=word_tokenize(data)\n",
        "text=nltk.Text(dat)\n",
        "unique=list(set(dat))\n",
        "datalen,vocabsize=len(data),len(unique)\n",
        "chartoint={b:a for a,b in enumerate(unique) }\n",
        "inttochar={a:b for a,b in enumerate(unique) }\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bt3yoFERecGm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "neuronno=1000\n",
        "lr=0.01\n",
        "timestamp=30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUZ5vkEcecQu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w1=2*np.random.random((vocabsize,neuronno))-1\n",
        "w2=2*np.random.random((neuronno,neuronno))-1\n",
        "w3=2*np.random.random((neuronno,vocabsize))-1\n",
        "b1=np.random.random((1,neuronno))\n",
        "b2=np.random.random((1,vocabsize))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DNzsO45dClyW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def travelintimestamp(inputs,target,ainitial):\n",
        "  x,y,a,p={},{},{},{}\n",
        "  a[-1]=np.copy(ainitial)   #size(1,neuron)\n",
        "  loss=0\n",
        "  for i in range(len(inputs)):\n",
        "    x[i]=np.zeros((1,vocabsize))\n",
        "    x[i][0,inputs[i]]=1\n",
        "    a[i]=np.tanh(np.dot(x[i],w1)+np.dot(a[i-1],w2)+b1)\n",
        "    y[i]=np.dot(a[i],w3)+b2\n",
        "    p[i]=np.exp(y[i])/np.sum(np.exp(y[i]))\n",
        "    loss+=(-np.log(p[i][0,target[i]]))\n",
        "    \n",
        "  dw1,dw2,dw3=np.zeros_like(w1),np.zeros_like(w2),np.zeros_like(w3)\n",
        "  db1,db2=np.zeros_like(b1),np.zeros_like(b2)\n",
        "  daprev=np.zeros_like(a[0])\n",
        "       \n",
        "  for i in reversed(range(len(inputs))):\n",
        "      dy=np.copy(p[i])\n",
        "      dy[0,target[i]]-=1\n",
        "      dw3+=np.dot(a[i].T,dy)\n",
        "      db2+=dy\n",
        "      da=np.dot(dy,w3.T)+daprev\n",
        "      dat=np.dot(da,(1-np.dot(a[i].T,a[i])))\n",
        "      db1+=dat\n",
        "      dw1+=np.dot(x[i].T,dat)\n",
        "      dw2+=np.dot(a[i-1].T,dat)\n",
        "      daprev=np.dot(dat,w2)\n",
        "           \n",
        "  return loss,dw1,dw2,dw3,db1,db2,a[len(inputs)-1]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-hBuI6HvCqj3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sampleoftext(a,randno,length):\n",
        "  x=np.zeros((1,vocabsize))\n",
        "  x[0,randno]=1\n",
        "  result=[]\n",
        "  for  i in range(length):\n",
        "    a=np.tanh(np.dot(x,w1)+np.dot(a,w2)+b1)\n",
        "    y=np.dot(a,w3)+b2\n",
        "    p=np.exp(y)/np.sum(np.exp(y))\n",
        "    \n",
        "    no=np.random.choice(range(vocabsize),p=p.ravel())\n",
        "    x=np.zeros((1,vocabsize))\n",
        "    x[0,no]=1\n",
        "    result.append(no)\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "51IV_A6qCwRW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a0c5b24-efcb-44d8-90bf-d1e5f3c510aa"
      },
      "cell_type": "code",
      "source": [
        "n,p=0,0\n",
        "sdw1=np.zeros_like(w1)\n",
        "sdw2=np.zeros_like(w2)\n",
        "sdw3=np.zeros_like(w3)\n",
        "sb1=np.zeros_like(b1)\n",
        "sb2=np.zeros_like(b2)\n",
        "weightedloss=0\n",
        "while True:\n",
        "  if p+timestamp>datalen or n==0:\n",
        "    ainitial=np.zeros((1,neuronno))\n",
        "    p=0\n",
        "  inputs= [chartoint[char] for char in text[p:p+timestamp]]\n",
        "  target= [chartoint[char] for char in text[p+1:p+timestamp+1]]\n",
        "  \n",
        "  loss,dw1,dw2,dw3,db1,db2,ainitial=travelintimestamp(inputs,target,ainitial)\n",
        "  weightedloss+=loss\n",
        "  if n%100==0:\n",
        "    print('loss',n,loss)\n",
        "    indexli=sampleoftext(ainitial,42,200)\n",
        "    print(' '.join([inttochar[index] for index in indexli]))\n",
        "    print('--------------------------------------------------------------------------------------')\n",
        "    \n",
        "  for par, dpar,s in zip([w1, w2, w3, b1, b2], [dw1, dw2, dw3, db1, db2], [sdw1, sdw2, sdw3, sb1, sb2]):\n",
        "    s=dpar*dpar\n",
        "    par-=lr*(dpar/np.sqrt(s+1e-7))\n",
        "    \n",
        "  p+=timestamp\n",
        "  n+=1\n",
        "  \n",
        "print(w1,w2,w3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('loss', 0, 2059.825997425463)\n",
            "Quilles temperately amaz or shent Weazell chide waste scape front Incontinencie easie Thunder wary Claudio Frailty vnwholsome obseruant Bedrid pins knife curles could now harrow distrust Reads Capitol indeauour out-breake dayes By thou'lt taints Collected none Heart holds wonder Gentrie sea-gowne Tragedie perturbed Wantonnesse shut Arrowes Treacherous crimes Starres Absent Orchard peace-parted Deuices Purse Compulsatiue giue shuffling folke primall Imagination betime bulke part wrote Nunnery Starre drown'd hoopes best saile Somnet those encountred gone Nephewes carries lying fashion Soales Cum Woodcocks limbes farewell Prisoner Saluation thirties Directly Abuses shift memory Battery demand Ardure Handsaw iangled Meet Such Lights first purg lippes preaching lend Saint Graces Chace tempt few therfore manner intreat Shippe suffer beautifed wisenesse ioyfully conueyance withdraw lockt wring Ambass Pardon Maiesties Obey Land Put kist Tutor fairely two answer clouds here own person faculty Booke present knotty breefe morning habite tormenting chaunted Spectators Inuestments stronger heauen-kissing certaine incens'd trifle eielids Absent tride harsh reueng natiue pith dearly How age might Challice mother Moreouer appear Tyrant reputation ore-wrought indeauour perturbed gratis Collection Feature Seal speed propertie see't Newtrall vpshot touching gratis throwne wormes Traueller Ominous glimpses excuse Whats shew busines conuerted seene stay grosser pittied enurn Sticke Passion dangerous\n",
            "--------------------------------------------------------------------------------------\n",
            "('loss', 100, 2116.5180345157396)\n",
            "woer yonder prou Like lipps Safely easily as Wall cease Remembrances Couch Theft carefully praises worst Conqueror her affliction sicknesse prepare King Receiues Cherube Illusion scape behold Stoopes pitteous Note not acts as Iigge aduenturous determination passes desires Hart hee image Keepes sweare diddest partiall Dies Soldier Begger 's Aunt Rebellious Selfe-slaughter , accurst fee monsters distrust carrying Armour Rose Saw releeued change Ioy demy-Natur'd ranke brow Wife Seal Best Hall despight on't sometime acquittance hermony Beautie terrible Quiddits you'l limbes gets muddied single Law hit equall wish thinkes flights Asse Libertine compell'd Get streame guilty wringing auoyd lookes varnish Begger Pitty sinewes ennactors Pioner vouchsafe conioyn death Vpon embracing Musick incensed Polake proclaime tast hop mortiz someuer Herod Wisedomes payed Damon middle wrinkled cheerefully thee Take Wash Moreouer Thicke Sence Maiesties which dutie moment clout admit manner reuerted cheefely furnish deceiu'd wing Cocke tragedie thicke heerein else finger vnhappily for thin necessary Beauty march maist Another Tempest expostulate batten weapons Mercy throughly foure flie ayde Romage Birch Pox doores aloofe Assignes liberall if shent reaks see't Reply presures Among gaming freely prate Without Contraction nonce moderate forgot Weazell faded fret Word iudge rebels Quintessence personall obstinate dislike visitation troubles\n",
            "--------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}